{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting an AB Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate sample size via power analysis\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def cohen_d(mean_1, mean_2, pooled_sd):\n",
    "    diff = (mean_1 - mean_2)\n",
    "    cohen_d = diff/pooled_sd\n",
    "    return(cohen_d)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "* Calculate Cohen's D for increasing click rate from 3% to 8%.\n",
    "* Assume the pooled standard deviation to be 14\n",
    "\n",
    "`Mean 1 - Mean 2 / pooled SD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.29411764705882354"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_d(5,10,17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the rule of thumb given by Cohen, how big of an effect size is this?\n",
    "\n",
    "\n",
    "Given this effect size, how many samples will we need to collect in order to not make a type II error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 250.843\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters \n",
    "\n",
    "effect = .29\n",
    "alpha = .05\n",
    "power = .9\n",
    "\n",
    "# Perform Power Analysis\n",
    "analysis = TTestIndPower()\n",
    "result = analysis.solve_power(effect, power=power, nobs1=None, ratio=1.0, alpha=alpha)\n",
    "print('Sample Size: %.3f' % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline Average was:  5.755426089179388\n",
      "The Experimental Average was:  8.60701214372206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.5508005846113657"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"experiment_data.csv\")\n",
    "\n",
    "print(\"The Baseline Average was: \", df['baseline'].mean())\n",
    "print(\"The Experimental Average was: \", df['experiment'].mean())\n",
    "\n",
    "bl = df['baseline'].mean()\n",
    "ex = df['experiment'].mean()\n",
    "\n",
    "ex_sd = df['experiment'].std()\n",
    "\n",
    "\n",
    "\n",
    "cohen_d(bl, ex, ex_sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The critical value is: -12.735895121086049\n",
      "The p value value is: 3.046638134432578e-29\n",
      "Degrees of Freedom: 262.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"experiment_data.csv\")\n",
    "\n",
    "df\n",
    "\n",
    "big_test = sm.stats.weightstats.ttest_ind(df['baseline'], \n",
    "                               df['experiment'], \n",
    "                               alternative='two-sided', \n",
    "                               usevar='pooled', value=0)\n",
    "                                                          \n",
    "                                                          \n",
    "print(\"The critical value is:\", big_test[0])\n",
    "print(\"The p value value is:\", big_test[1])                                                          \n",
    "print(\"Degrees of Freedom:\", big_test[2]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB Interpretation.ipynb   create_dummy_data.R       experiment_data_small.csv\r\n",
      "README.md                 experiment_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn! \n",
    "\n",
    "Find the file `experiment_data_small.csv` in the current working directory and run a t-test on this data.\n",
    "\n",
    "* First report the p value of the test\n",
    "* Second, write a statement on what the p value means\n",
    "* Third, use the function from above to calculate the effect size\n",
    "* Fourth, write a paragraph reccomending if we should adopt the change made by the second AB test we have run!\n",
    "\n",
    "Be prepared to be assigned to a side where you advocate for adopting the new change or not adopting the new change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "                     dv = pd.read_csv(\"~/desktop/tre/ab-testing-london-ds/experiment_data_small.csv\")                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(dv['baseline_small'])\n",
    "x_bar = np.mean(dv['experiment_small'])\n",
    "sigma = np.std(dv['experiment_small'])\n",
    "base_std = np.std(dv['baseline_small'])\n",
    "n = len(dv['baseline_small'])\n",
    "alpha = 0.05\n",
    "    \n",
    "t_value = (x_bar-mu)/(sigma/np.sqrt(n))\n",
    "p = 1-stats.norm.cdf(t_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.21510564594203, 0.013376407003477642)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_value, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The p-value indicates how extreme the data is. In this particular case, because the p-value is less than the alpha, we reject the null hypothesis, and we can say the result is statistically significant.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The p-value indicates how extreme the data is. In this particular case, because the p-value is less than the alpha, we reject the null hypothesis, and we can say the result is statistically significant.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = (((sigma**2) + (base_std**2))/2)\n",
    "def effect_size(mean_1, mean_2, pooled_sd):\n",
    "    diff = (mean_1 - mean_2)\n",
    "    e_s = diff/pooled_sd\n",
    "    return(e_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03264701152876203"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect_size(x_bar, mu, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Based on the results, we should adopt the changes by the second AB test,\n",
    "but with percautions.\n",
    "First, p_value shows that there is a change on the second test(p_value > alpha),\n",
    "but based on the effect size value, .032, the magnitude of the experiment \n",
    "effect is small, indicating a weak difference between the tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
